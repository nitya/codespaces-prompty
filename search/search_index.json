{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Prompty Workshop","text":""},{"location":"#objectives","title":"Objectives","text":"<p>Learn Prompty concepts and usage with hands-on exercises.</p> <ul> <li>Understand the specification (asset format)</li> <li>Get familiar with the tooling (Prompty extension, SDK, CLI)</li> <li>Get familiar with the runtime (core, frameworks)</li> </ul> Pre-Requisites: What you need (before you begin) <ul> <li>Need a GitHub account (Codespaces, Marketplace access)</li> <li>Need an Azure account (for some exercises)</li> <li>Familiarity with Python, Jupyter Notebooks (language)</li> <li>Familiarity with VS Code, GitHub (tools)</li> <li>Familiarity with generative AI concepts (prompts, models, AIOps)</li> </ul> Post-Workshop: What can you do with this sandbox? <ul> <li>Template repository can be instantiated to start new projects</li> <li>Use GitHub Marketplace to explore impact of model choice </li> <li>Use Azure AI Model Inference API to abstract model usage</li> <li>Use Prompty code generation to orchestrate complex flows</li> <li>Use Prompty assets to build &amp; understand custom evaluators</li> <li>Use Prompty traces to debug &amp; understand app performance</li> </ul>"},{"location":"#resources","title":"Resources","text":"<p>Start by watching this breakout session from Microsoft Build 2024. The session takes you from learning core concepts to practical usage for building end-to-end applications with Azure AI.</p> <p>Then check out three core resources:</p> <ul> <li>Prompty Documentation</li> <li>Prompty Repositoryhttps://github.com/Microsoft/prompty/</li> <li>Azure AI Templates</li> </ul>"},{"location":"1-Concepts/","title":"Overview","text":""},{"location":"1-Concepts/#motivation","title":"Motivation","text":"<p>Building generative AI applications requires a process of repeated iterations from prompt design to production deployment. Generative AI Ops defines the app lifecycle in three stages, as shown:</p> <ol> <li>Ideation - building the initial prototype.</li> <li>Evaluation - assessing prototype for quality and safety</li> <li>Operationalization - deploying prototype to production</li> </ol> <p>The challenge for developers lies in reducing the time and complexity associated with the first two stages, so they can move more quickly from designing the initial prompt to having a production-ready deployment.</p> <p></p>"},{"location":"1-Concepts/#what-is-prompty","title":"What is Prompty?","text":"<p>Prompty is an open-source project from Microsoft that brings agency with observability to the prompt engineering and rapid prototyping process. It contists of three components:</p> <ul> <li>Specification - defining the file format for versionable <code>.prompty</code> assets.</li> <li>Tooling - simplifying developer experience in creating and managing those assets.</li> <li>Runtime - converting assets to code for interactive testing &amp; orchestated workflows.</li> </ul> <p></p> <p>With Prompty, you effectively get a playground in your IDE, with three critical features for developers:</p> <ul> <li>Customizability - easily switch &amp; configure models and behaviors for prompt engineering </li> <li>Composability - think \"micro-orchestrators\" that can be composed into more complex flows </li> <li>Observability - debug and analyze workflows with trace data and visualizations</li> </ul> <p>When we say Prompty has \"agency with observability\", we mean that it gives us the power to customize and compose models and behaviors at the granularity of a single LLM call - then empowers us to trace the execution of the calls from request to response to understand and optimize for cost or performance.</p>"},{"location":"1-Concepts/#where-to-use-prompty","title":"Where to use Prompty?","text":"<p>The basic building block of the generative AI application is the API call- a request is made (user prompt), gets processed by a language model (inference task), and the response gets delivered back to the user (result).</p> <p>Based on use case, the \"processing\" step can expand into more complex workflows (e.g., retrieval augmented generation, multi-agent conversations etc.) that require orchestration of multiple models and services. This has led to orchestration frameworks like Prompt flow, LangChain and Semantic Kernel that manage data flow and async interaction requirements for the application.</p> <p>But it also leaves a gap (and opportunity) for micro-orchestrators that handle expanded processing and optimization for a single API call (step) before tackling multi-model, multi-step workflows. These micro-orchestrators should be lightweight, composable and observable. Prompty was designed to fill this gap.</p> <p>Developers can now \"unit test\" Prompty assets for quality and safety before using them with higher-level frameworks to orchestrsate complex workflows. Those frameworks can now focus on \"integration\" and \"end-to-end\" testing of the workflows, knowing that base component quality and safety requirements were already validated.</p> <p></p>"},{"location":"1-Concepts/#how-to-use-prompty","title":"How to use Prompty","text":"<p>Prompty is designed to be used in the early stages of the generative AI application lifecycle, where developers are designing and testing prompts for quality and safety. </p> <ol> <li>Design your application by creating a Prompty asset with a default model and prompt.</li> <li>Develop your prototype by iterating on model (configuration) and prompt (template).</li> <li>Evaluate your prototype for quality and safety using custom Prompty evaluators (runtime)</li> </ol> <p>It is in the last step that we can take advantage of Prompty tooling that interfaces to popular orchestration frameworks to chain together chat and evaluation Prompty assets for assessing quality against a more diverse set of input request prompts.</p> <p></p>"},{"location":"1-Concepts/1-Specification/","title":"Prompty Specification","text":"<p>Prompty assets are represented by files with a <code>.prompty</code> extension and must follow the schema outlined in the Prompty Specification. </p>"},{"location":"1-Concepts/1-Specification/#1-specification-schema","title":"1. Specification: Schema","text":"<p>We can now revisit the Prompty Specification to get the full picture of the Prompty asset schema. Let's start by recongizing the top-level sections:</p> <ul> <li><code>$schema</code> - the schema version used for validation</li> <li><code>$id</code> - the unique identifier for the schema</li> <li><code>title</code> - the title of the schema</li> <li><code>description</code> - a brief description of the schema</li> <li><code>type</code> - the type of the schema (here, \"object\")</li> <li><code>additionalProperties</code> - whether additional properties are allowed (here, \"false\")</li> <li><code>properties</code> - the properties of the schema</li> <li><code>definitions</code> - the definitions used in the schema</li> </ul> Specificaton file: <code>prompty.yaml</code> YAML<pre><code>    # This schema represents the specification file for the prompty\n# _frontmatter_, not the content section.\n\n$schema: http://json-schema.org/draft-07/schema#  \n$id: http://azureml/sdk-2-0/Prompty.yaml  \ntitle: Prompty front matter schema specification  \ndescription: A specification that describes how to provision a new prompty using definition frontmatter.\ntype: object \n\nadditionalProperties: false\n\nproperties:\n$schema:\n    type: string\n# metadata section\nmodel:\n    type: object\n    additionalProperties: false\n    properties:\n    api:\n        type: string\n        enum: \n        - chat\n        - completion\n        description: The API to use for the prompty -- this has implications on how the template is processed and how the model is called.\n        default: chat\n\n    configuration:\n        oneOf:\n        - $ref: \"#/definitions/azureOpenaiModel\"\n        - $ref: \"#/definitions/openaiModel\"\n        - $ref: \"#/definitions/maasModel\"\n\n    parameters:\n        $ref: \"#/definitions/parameters\"\n\n    response: \n        type: string\n        description: This determines whether the full (raw) response or just the first response in the choice array is returned.\n        default: first \n        enum:\n        - first\n        - full\n\n\nname:\n    type: string\n    description: Name of the prompty\ndescription:\n    type: string\n    description: Description of the prompty\nversion:\n    type: string\n    description: Version of the prompty\nauthors:\n    type: array\n    description: Authors of the prompty\n    items:\n    type: string\ntags:\n    type: array\n    description: Tags of the prompty\n    items:\n    type: string\n\n# not yet supported -- might add later\n# base:\n#   type: string\n#   description: The base prompty to use as a starting point\n\nsample: \n    oneOf:\n    - type: object\n        description: The sample to be used in the prompty test execution\n        additionalProperties: true\n    - type: string\n        description: The file to be loaded to be used in the prompty test execution\n\n# the user can provide a single sample in a file or specify the data inline\n# sample:\n#   messages: \n#     - role: user\n#       content: where is the nearest coffee shop?\n#     - role: system\n#       content: I'm sorry, I don't know that. Would you like me to look it up for you?\n# or point to a file\n# sample: sample.json\n# also the user can specify the data on the command line\n# pf flow test --flow p.prompty --input my_sample.json\n# if the user runs this command, the sample from the prompty will be used\n# pf flow test --flow p.prompty   \n\ninputs:\n    type: object\n    description: The inputs to the prompty\n\noutputs:\n    type: object\n    description: The outputs of the prompty\n\n# currently not supported -- might not be needed\n# init_signature:\n#   type: object\n#   description: The signature of the init function\n\ntemplate:\n    type: string\n    description: The template engine to be used can be specified here. This is optional.\n    enum: [jinja2]\n    default: jinja2\n\ndefinitions:\n</code></pre> <p>Here, </p> <ul> <li>properties describe valid \"keys\" that can be present in a <code>.prompty</code> asset file,</li> <li>definitions describe \"reusable\" schema definitions\" for quick reference in properties</li> </ul> <p>Let's take a look at Prompty schema properties and definitions in more detail.</p>"},{"location":"1-Concepts/1-Specification/#11-specification-properties","title":"1.1 Specification: Properties","text":"<p>The properties schema describes these valid \"keys\" that can be present in a <code>.prompty</code> asset file:</p> <ul> <li><code>$schema</code> - (string) the schema version used for validation</li> <li><code>model</code> - (object) the model configuration for the asset<ul> <li><code>api</code> - (string) the API type (<code>chat</code> (default) or <code>completion</code>)</li> <li><code>configuration</code> - (object) one of definitions provided</li> <li><code>parameters</code> - (object) from definitions provided</li> <li><code>response</code> - (string) whether to return <code>full</code> or <code>first</code> response (default: first)</li> </ul> </li> <li><code>name</code> - (string) the name of the asset</li> <li><code>description</code> - (string) a brief description of the asset</li> <li><code>version</code> - (string) the version of the asset</li> <li><code>authors</code> - (array) a list of authors who contributed to the asset</li> <li><code>tags</code> - (array) a list of tags for the asset</li> <li><code>sample</code> - test data for validation - can be object (inline) or string (filename)</li> <li><code>inputs</code> - (object) defining request properties for prompty asset</li> <li><code>outputs</code> - (object) defining response properties for prompty asset</li> <li><code>template</code> - (string) the template engine to be used (default: <code>jinja2</code>)</li> </ul>"},{"location":"1-Concepts/1-Specification/#12-specification-definitions","title":"1.2 Specification: Definitions","text":"<p>The <code>definitions</code> section of the schema describes reusable schema sections that can then be referenced within the <code>properties</code> section with the <code>$ref</code> keyword. For example, this is in <code>model</code> properties:</p> YAML<pre><code>    configuration:\n        oneOf:\n        - $ref: \"#/definitions/azureOpenaiModel\"\n        - $ref: \"#/definitions/openaiModel\"\n        - $ref: \"#/definitions/maasModel\"\n\n    parameters:\n        $ref: \"#/definitions/parameters\"\n</code></pre> <p>This lets us define complex schema once and reference it in multiple places without duplication of content - helping keep the specification readable and maintainable.</p> <p>The specification has 3 definitions for Model: Configuration:</p> Definition: <code>openaiModel</code> configuration for Model YAML<pre><code># vanilla openai models\nopenaiModel:\n    type: object\n    description: Model used to generate text\n    properties:\n    type:\n        type: string\n        description: Type of the model\n        const: openai\n    name:\n        type: string\n        description: Name of the model\n    organization:\n        type: string\n        description: Name of the organization\n    additionalProperties: false\n</code></pre> Definition: <code>azurOpenaiModel</code> configuration for Model YAML<pre><code># azure openai models\nazureOpenaiModel:\n    type: object\n    description: Model used to generate text\n    properties:\n    type:\n        type: string\n        description: Type of the model\n        const: azure_openai\n    api_version:\n        type: string\n        description: Version of the model\n    azure_deployment:\n        type: string\n        description: Deployment of the model\n    azure_endpoint:\n        type: string\n        description: Endpoint of the model\n    additionalProperties: false\n</code></pre> Definition: <code>maasModel</code> configuration for Model YAML<pre><code># for maas models\nmaasModel:\n    type: object\n    description: Model used to generate text\n    properties:\n    type:\n        type: string\n        description: Type of the model\n        const: azure_serverless\n    azure_endpoint:\n        type: string\n        description: Endpoint of the model\n    additionalProperties: false\n</code></pre> <p>The specification has 1 definition for Model: Parameters. For now, it defines these as common to all models (where individual models may process each differently). </p> <p>The paramters are: response_format, seed, max_tokens, temperature, tools_choice, tools, frequency_penalty, presence_penalty, stop, and top_p. Click to expand for details.</p> Definition: <code>parameters</code> for Model YAML<pre><code># parameters for the model -- for now these are not per model but the same for all models\nparameters:\n    type: object\n    description: Parameters to be sent to the model \n    additionalProperties: true\n    properties: \n    response_format: \n        type: object\n        description: &gt;\n        An object specifying the format that the model must output. Compatible with\n        `gpt-4-1106-preview` and `gpt-3.5-turbo-1106`.\n        Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n        message the model generates is valid JSON.\n\n    seed:\n        type: integer\n        description: &gt; \n        This feature is in Beta. If specified, our system will make a best effort to\n        sample deterministically, such that repeated requests with the same `seed` and\n        parameters should return the same result. Determinism is not guaranteed, and you\n        should refer to the `system_fingerprint` response parameter to monitor changes\n        in the backend.\n\n    max_tokens:\n        type: integer\n        description: The maximum number of [tokens](/tokenizer) that can be generated in the chat completion.\n\n    temperature:\n        type: number\n        description: What sampling temperature to use, 0 means deterministic.\n\n    tools_choice:\n        oneOf:\n        - type: string\n        - type: object\n\n        description: &gt; \n        Controls which (if any) function is called by the model. `none` means the model\n        will not call a function and instead generates a message. `auto` means the model\n        can pick between generating a message or calling a function. Specifying a\n        particular function via\n        `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n        call that function.\n\n        `none` is the default when no functions are present. `auto` is the default if\n        functions are present.\n\n    tools:\n        type: array\n        items:\n        type: object\n\n    frequency_penalty:\n        type: number\n        description: What sampling frequency penalty to use. 0 means no penalty.\n\n    presence_penalty:\n        type: number\n        description: What sampling presence penalty to use. 0 means no penalty.\n\n    stop:\n        type: array\n        items:\n        type: string\n        description: &gt; \n        One or more sequences where the model should stop generating tokens. The model\n        will stop generating tokens if it generates one of the sequences. If the model\n        generates a sequence that is a prefix of one of the sequences, it will continue\n        generating tokens.\n\n    top_p:\n        type: number\n        description: &gt; \n        What nucleus sampling probability to use. 1 means no nucleus sampling. 0 means\n        no tokens are generated.\n</code></pre>"},{"location":"1-Concepts/1-Specification/#2-asset-example","title":"2. Asset: Example","text":"<p>To get a practical sense for specification usage, let's look at an example Prompty asset file. Use the Prompty Visual Studio Code extension to generate the default <code>.prompty</code> starter file as follows:</p> <ul> <li>open the file-explorer window (left) in Visual Studio Code</li> <li>right-click on the folder where you want to create the <code>.prompty</code> file</li> <li>select <code>New Prompty File</code> from the context menu</li> </ul> <p>You should see something like this - we'll demysystify the contents, next.</p> Asset file: <code>basic.prompty</code> Markdown<pre><code>---\nname: ExamplePrompt\ndescription: A prompt that uses context to ground an incoming question\nauthors:\n- Seth Juarez\nmodel:\n    api: chat\n    configuration:\n        type: azure_openai\n        azure_endpoint: ${env:AZURE_OPENAI_ENDPOINT}\n        azure_deployment: &lt;your-deployment&gt;\n        api_version: 2024-07-01-preview\n    parameters:\n        max_tokens: 3000\nsample:\n    firstName: Seth\n    context: &gt;\n        The Alpine Explorer Tent boasts a detachable divider for privacy, \n        numerous mesh windows and adjustable vents for ventilation, and \n        a waterproof design. It even has a built-in gear loft for storing \n        your outdoor essentials. In short, it's a blend of privacy, comfort, \n        and convenience, making it your second home in the heart of nature!\n    question: What can you tell me about your tents?\n---\n\nsystem:\nYou are an AI assistant who helps people find information. As the assistant, \nyou answer questions briefly, succinctly, and in a personable manner using \nmarkdown and even add some personal flair with appropriate emojis.\n\n# Customer\nYou are helping {{firstName}} to find answers to their questions.\nUse their name to address them in your responses.\n\n# Context\nUse the following context to provide a more personalized response to {{firstName}}:\n{{context}}\n\nuser:\n{{question}}\n</code></pre>"},{"location":"1-Concepts/1-Specification/#21-asset-frontmatter","title":"2.1 Asset: Frontmatter","text":"<p>The frontmatter section of the asset occurs between the <code>---</code> delimiters (lines 1-24 above) and contains metadata about the asset. Let's take a look at just this segment below.</p> <p>We see the following properties used in the frontmatter:</p> <ul> <li><code>name</code> - default name is \"ExamplePrompt\" (change it)</li> <li><code>description</code> - default description given (change it)</li> <li><code>authors</code> - default author given (change it)</li> <li><code>model</code> - the model configuration for the asset<ul> <li><code>api</code> - set to default (\"chat\")</li> <li><code>configuration</code> - set to default (\"azure_openai\")</li> <li><code>parameters</code> - sets <code>max_tokens</code> to 3000</li> </ul> </li> <li><code>sample</code> - set to inline object (not filename) with 3 properties<ul> <li><code>firstName</code> - default requestor name (change it)</li> <li><code>context</code> - gives example \"grounding\" data (change it)</li> <li><code>question</code> - default user question (change it)</li> </ul> </li> </ul> <p>The frontmatter is used by Prompty tooling and runtime to understand the asset and its requirements for execution. The sample is key to allowing us to iteratively build the \"shape\" of our data with local testing, before integrating with external services to fetch real data that matches this shape.</p> Asset Frontmatter: <code>basic.prompty</code> Markdown<pre><code>---\nname: ExamplePrompt\ndescription: A prompt that uses context to ground an incoming question\nauthors:\n- Seth Juarez\nmodel:\n    api: chat\n    configuration:\n        type: azure_openai\n        azure_endpoint: ${env:AZURE_OPENAI_ENDPOINT}\n        azure_deployment: &lt;your-deployment&gt;\n        api_version: 2024-07-01-preview\n    parameters:\n        max_tokens: 3000\nsample:\n    firstName: Seth\n    context: &gt;\n        The Alpine Explorer Tent boasts a detachable divider for privacy, \n        numerous mesh windows and adjustable vents for ventilation, and \n        a waterproof design. It even has a built-in gear loft for storing \n        your outdoor essentials. In short, it's a blend of privacy, comfort, \n        and convenience, making it your second home in the heart of nature!\n    question: What can you tell me about your tents?\n---\n</code></pre>"},{"location":"1-Concepts/1-Specification/#22-asset-template","title":"2.2 Asset: Template","text":"<p>The template section of the asset occurs below the second <code>---</code> delimiters (lines 24-end in example above) and provides the content for the prompt template. Let's take a look at just this segment below.</p> <p>A prompt template typically defines the persona, instructions and primary content (e.g., cues, examples) for the inference task that we want the model to execute. We see the following properties used in the template section for this purpose:</p> <ul> <li><code>system</code> - establishes default persona (AI assistant to help ..) and instructions (answer briefly ...)<ul> <li><code>Customer</code> -  data shape for \"Customer\" with instructions (\"address them by name\")</li> <li><code>Context</code> - data shape for \"Grounding Context\" with instructions (\"personalize response\")</li> </ul> </li> <li><code>user</code> - defines the user prompt (actual incoming request)</li> </ul> <p>The <code>{{&lt;variable-name&gt;}}</code> syntax used in the template denotes placeholders for data that will be bound in, when the template is instantiated at runtime. Note how each of those variables typically has a value defined in the sample object, for testing purposes. This allows us to get a sense for the shape of data we expect to retrieve and augment (from third-party services or from flow orchestration) as we iterate and engineer the prompt.</p> Asset Template: <code>basic.prompty</code> Markdown<pre><code>system:\nYou are an AI assistant who helps people find information. As the assistant, \nyou answer questions briefly, succinctly, and in a personable manner using \nmarkdown and even add some personal flair with appropriate emojis.\n\n# Customer\nYou are helping {{firstName}} to find answers to their questions.\nUse their name to address them in your responses.\n\n# Context\nUse the following context to provide a more personalized response to {{firstName}}:\n{{context}}\n\nuser:\n{{question}}\n</code></pre>"},{"location":"1-Concepts/2-Tooling/","title":"Prompty Tooling","text":""},{"location":"1-Concepts/3-Runtime/","title":"Prompty Runtime","text":""},{"location":"2-Quickstart/","title":"2. Quickstart","text":"<ol> <li>Create Prompty Asset </li> <li>Explore Prompty Asset</li> <li>Configure &amp; Run Prompty - from Extension</li> <li>Create Prompty Code</li> <li>Explore Prompty Code</li> <li>Run Prompty Code - from Extension</li> <li>Run Prompty Code - from Terminal</li> </ol>"},{"location":"2-Quickstart/#app-development","title":"App Development","text":"<ol> <li>Learn Concepts</li> <li>My First Prompty</li> <li>Configure Frontmatter</li> <li>Configure Template</li> <li>Configure Data Shape</li> <li>Chain Prompty Assets</li> <li>Build RAG-Chat Flow</li> <li>Build Multi-Agent Flow</li> </ol>"},{"location":"2-Quickstart/#model-choice","title":"Model Choice","text":"<ol> <li>Use Serverless Models</li> <li>Use Azure OpenAI Models</li> <li>Use OpenAI Models</li> <li>Use </li> </ol>"},{"location":"3-Build/","title":"Build With Prompty","text":""},{"location":"4-Evaluate/","title":"Evaluate with Prompty","text":""},{"location":"5-Trace/","title":"Trace Prompty Runs","text":""},{"location":"6-Orchestrate/","title":"Orchestrate Flows","text":""},{"location":"7-Extend/","title":"Extending Prompty","text":""},{"location":"7-Extend/#add-new-runtime","title":"Add New Runtime","text":""},{"location":"7-Extend/#add-new-invoker","title":"Add New Invoker","text":""},{"location":"7-Extend/#validate-new-model","title":"Validate New Model","text":""},{"location":"7-Extend/#other-contributions","title":"Other Contributions","text":""}]}